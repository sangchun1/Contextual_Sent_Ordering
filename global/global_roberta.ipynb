{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 12014679,
          "sourceType": "datasetVersion",
          "datasetId": 7558757
        }
      ],
      "dockerImageVersionId": 31040,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "83f169fb379640bf86dbebafdcb8beee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5582fbaf7b2c4454abad09f68a82ffd0",
              "IPY_MODEL_83e3cba167974e7ab1d155f24bc931b8",
              "IPY_MODEL_4c066b88aed74ab786bd11abc3efa77b"
            ],
            "layout": "IPY_MODEL_869d964efd0244cb9121f42d66325542"
          }
        },
        "5582fbaf7b2c4454abad09f68a82ffd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c6a54e670684cbd8b105a8a094678e7",
            "placeholder": "​",
            "style": "IPY_MODEL_3cd7d0f3436449fa9b861789ddae30bb",
            "value": "config.json: 100%"
          }
        },
        "83e3cba167974e7ab1d155f24bc931b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccc143d7eb824bde97a3f8b814691c0a",
            "max": 547,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2574c9e9e5c946dfaed6acc1e52cb907",
            "value": 547
          }
        },
        "4c066b88aed74ab786bd11abc3efa77b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4abc006a1434a0da24304d4a49d29bf",
            "placeholder": "​",
            "style": "IPY_MODEL_f6691e7265e5472e8d3b9612f5cc2b94",
            "value": " 547/547 [00:00&lt;00:00, 67.7kB/s]"
          }
        },
        "869d964efd0244cb9121f42d66325542": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c6a54e670684cbd8b105a8a094678e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3cd7d0f3436449fa9b861789ddae30bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ccc143d7eb824bde97a3f8b814691c0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2574c9e9e5c946dfaed6acc1e52cb907": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f4abc006a1434a0da24304d4a49d29bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6691e7265e5472e8d3b9612f5cc2b94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f3585241baf04490a9fc6ccf611c731a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_83e4b9a04e694a70be269f7f26eabc15",
              "IPY_MODEL_e387edd818c34a57a7457782d3db3b2e",
              "IPY_MODEL_9f3fdc17e5c64c0ca901dbb8914e5d74"
            ],
            "layout": "IPY_MODEL_05d96bcb9e2144989bdfaf7b1cd6c8af"
          }
        },
        "83e4b9a04e694a70be269f7f26eabc15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82599d47451a4509a2fa181fb8d393ae",
            "placeholder": "​",
            "style": "IPY_MODEL_c5605dc04126455abede39f423c2fcfc",
            "value": "model.safetensors: 100%"
          }
        },
        "e387edd818c34a57a7457782d3db3b2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64ce0266992c4d178416dd3d9f6676f7",
            "max": 1346814194,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1a415f83ccf54c40a5cffc579c9806c2",
            "value": 1346814194
          }
        },
        "9f3fdc17e5c64c0ca901dbb8914e5d74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b861f9f5cf6848a882a6a12d8b88b5b6",
            "placeholder": "​",
            "style": "IPY_MODEL_37ff70ed35bd462883e18b993fe5b39e",
            "value": " 1.35G/1.35G [00:04&lt;00:00, 326MB/s]"
          }
        },
        "05d96bcb9e2144989bdfaf7b1cd6c8af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82599d47451a4509a2fa181fb8d393ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5605dc04126455abede39f423c2fcfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "64ce0266992c4d178416dd3d9f6676f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a415f83ccf54c40a5cffc579c9806c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b861f9f5cf6848a882a6a12d8b88b5b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37ff70ed35bd462883e18b993fe5b39e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/onewon1234/AI_DL_Project/blob/main/global/global_roberta_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import loguniform\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "import itertools\n",
        "from itertools import permutations\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModel,\n",
        "    AutoModelForSequenceClassification,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    EarlyStoppingCallback\n",
        ")"
      ],
      "metadata": {
        "id": "7FIQKoH2qvyZ",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-01T03:00:14.753407Z",
          "iopub.execute_input": "2025-06-01T03:00:14.753640Z",
          "iopub.status.idle": "2025-06-01T03:00:42.075447Z",
          "shell.execute_reply.started": "2025-06-01T03:00:14.753623Z",
          "shell.execute_reply": "2025-06-01T03:00:42.074853Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "a4hMUXbK0UIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8Ezv7ZKqvya",
        "outputId": "ef5ca680-e327-40d0-fe69-63db4849f038",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-01T08:15:35.605388Z",
          "iopub.execute_input": "2025-06-01T08:15:35.606019Z",
          "iopub.status.idle": "2025-06-01T08:15:35.715969Z",
          "shell.execute_reply.started": "2025-06-01T08:15:35.605996Z",
          "shell.execute_reply": "2025-06-01T08:15:35.715222Z"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/강의/AI를 위한 딥러닝/AI_DL_Project/code"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PT30-RU7vslh",
        "outputId": "f0ea5069-a628-4cf8-8848-b813a4cf75d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/강의/AI를 위한 딥러닝/AI_DL_Project/code'\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 로드\n",
        "train_path = pd.read_csv('/content/drive/MyDrive/data/daycon_sentence/train.csv')\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/data/daycon_sentence/test.csv')\n",
        "submission_path = pd.read_csv('/content/drive/MyDrive/data/daycon_sentence/sample_submission.csv')"
      ],
      "metadata": {
        "id": "Abf6t3Zwvtv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission_path = pd.read_csv(BASE_DIR + \"sample_submission.csv\")"
      ],
      "metadata": {
        "id": "vUpT4LF3qvyb",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-01T03:00:42.426770Z",
          "iopub.execute_input": "2025-06-01T03:00:42.426997Z",
          "iopub.status.idle": "2025-06-01T03:00:42.450380Z",
          "shell.execute_reply.started": "2025-06-01T03:00:42.426979Z",
          "shell.execute_reply": "2025-06-01T03:00:42.449726Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "ef860e98-4d99-4c5d-f774-ed76cebe8146"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'BASE_DIR' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-aef237bc8d0e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msubmission_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBASE_DIR\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"sample_submission.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'BASE_DIR' is not defined"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "submission_path.info()\n",
        "submission_path.head()"
      ],
      "metadata": {
        "id": "5nkFL-jSqvyc",
        "outputId": "03b3eee7-7784-4828-e90e-cbf48df94ea3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-01T03:00:42.451170Z",
          "iopub.execute_input": "2025-06-01T03:00:42.451424Z",
          "iopub.status.idle": "2025-06-01T03:00:42.474622Z",
          "shell.execute_reply.started": "2025-06-01T03:00:42.451402Z",
          "shell.execute_reply": "2025-06-01T03:00:42.473927Z"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1780 entries, 0 to 1779\n",
            "Data columns (total 5 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   ID        1780 non-null   object\n",
            " 1   answer_0  1780 non-null   int64 \n",
            " 2   answer_1  1780 non-null   int64 \n",
            " 3   answer_2  1780 non-null   int64 \n",
            " 4   answer_3  1780 non-null   int64 \n",
            "dtypes: int64(4), object(1)\n",
            "memory usage: 69.7+ KB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          ID  answer_0  answer_1  answer_2  answer_3\n",
              "0  TEST_0000         0         1         2         3\n",
              "1  TEST_0001         0         1         2         3\n",
              "2  TEST_0002         0         1         2         3\n",
              "3  TEST_0003         0         1         2         3\n",
              "4  TEST_0004         0         1         2         3"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1bf15d63-2b28-4fc7-941a-56afeaf560f9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>answer_0</th>\n",
              "      <th>answer_1</th>\n",
              "      <th>answer_2</th>\n",
              "      <th>answer_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TEST_0000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TEST_0001</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TEST_0002</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TEST_0003</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TEST_0004</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1bf15d63-2b28-4fc7-941a-56afeaf560f9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1bf15d63-2b28-4fc7-941a-56afeaf560f9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1bf15d63-2b28-4fc7-941a-56afeaf560f9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-05c84313-67ac-4875-8c94-c4ece50470d3\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-05c84313-67ac-4875-8c94-c4ece50470d3')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-05c84313-67ac-4875-8c94-c4ece50470d3 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "submission_path",
              "summary": "{\n  \"name\": \"submission_path\",\n  \"rows\": 1780,\n  \"fields\": [\n    {\n      \"column\": \"ID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1780,\n        \"samples\": [\n          \"TEST_1647\",\n          \"TEST_1301\",\n          \"TEST_0944\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer_0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer_1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer_2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2,\n        \"max\": 2,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer_3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 3,\n        \"max\": 3,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# data_utils.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def load_data(train_path, test_path):\n",
        "    train = pd.read_csv(train_path)\n",
        "    test = pd.read_csv(test_path)\n",
        "    return train, test\n",
        "\n",
        "def make_labels(df):\n",
        "    # answer_0 ~ answer_3 → [문장0은 몇 번째, 문장1은 몇 번째, ...]\n",
        "    answers = df[[f'answer_{i}' for i in range(4)]].values\n",
        "    labels = []\n",
        "    for row in answers:\n",
        "        label = [0]*4\n",
        "        for pos, sent_idx in enumerate(row):\n",
        "            label[sent_idx] = pos\n",
        "        labels.append(label)\n",
        "    return np.array(labels)"
      ],
      "metadata": {
        "id": "gnF7yb6oqvyc",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-01T03:00:42.475322Z",
          "iopub.execute_input": "2025-06-01T03:00:42.475540Z",
          "iopub.status.idle": "2025-06-01T03:00:42.493164Z",
          "shell.execute_reply.started": "2025-06-01T03:00:42.475523Z",
          "shell.execute_reply": "2025-06-01T03:00:42.492316Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset 클래스\n",
        " 4개의 문장을 [SEP]로 묶어서 BERT에 넣을 수 있게 바꿔줌"
      ],
      "metadata": {
        "id": "mAdqOCQFqvyd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ 1. 데이터셋 클래스\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class GlobalOrderDataset(Dataset):\n",
        "    def __init__(self, df, tokenizer, labels=None, max_length=256):\n",
        "        self.sentences = df[[f'sentence_{i}' for i in range(4)]].values\n",
        "        self.tokenizer = tokenizer\n",
        "        self.labels = labels\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sentences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sents = self.sentences[idx]\n",
        "        text = '[CLS] ' + ' [SEP] '.join(sents) + ' [SEP]'\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        item = {k: v.squeeze(0) for k, v in encoding.items()}\n",
        "        if self.labels is not None:\n",
        "            item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "            return item\n"
      ],
      "metadata": {
        "id": "OnATscUgqvyg",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-01T03:00:42.493798Z",
          "iopub.execute_input": "2025-06-01T03:00:42.494067Z",
          "iopub.status.idle": "2025-06-01T03:00:42.509629Z",
          "shell.execute_reply.started": "2025-06-01T03:00:42.494050Z",
          "shell.execute_reply": "2025-06-01T03:00:42.509047Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 클래스\n",
        "- AutoModel (예: Roberta) 사용\n",
        "- 문장 4개를 넣었을 때 그 순서를 예측\n",
        "- 출력은 [batch, 4, 4] 크기의 행렬 → 각 문장이 어떤 위치에 있어야 하는지 예측"
      ],
      "metadata": {
        "id": "8_pTePS6qvyh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ 2. 모델 정의\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoModel\n",
        "class GlobalOrderModel(nn.Module):\n",
        "    def __init__(self, model_name='klue/roberta-large'):\n",
        "        super().__init__()\n",
        "        self.bert = AutoModel.from_pretrained(model_name)\n",
        "        hidden_size = self.bert.config.hidden_size\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_size, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(1024, 4 * 4)  # 4문장 * 4 클래스\n",
        "        )\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled = outputs.last_hidden_state[:, 0]  # [CLS] 토큰 기준\n",
        "        logits = self.classifier(pooled)\n",
        "        if labels is not None:\n",
        "            loss_fn = nn.CrossEntropyLoss()\n",
        "            loss = loss_fn(logits.view(-1, 4), labels.view(-1))\n",
        "            return {\"loss\": loss, \"logits\": logits.view(-1, 4, 4)}  # ✅ 여기가 핵심!\n",
        "        else:\n",
        "            return {\"logits\": logits.view(-1, 4, 4)}\n"
      ],
      "metadata": {
        "id": "UzOnQquWqvyh",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-01T03:00:42.510432Z",
          "iopub.execute_input": "2025-06-01T03:00:42.510691Z",
          "iopub.status.idle": "2025-06-01T03:00:42.528493Z",
          "shell.execute_reply.started": "2025-06-01T03:00:42.510667Z",
          "shell.execute_reply": "2025-06-01T03:00:42.527768Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    try:\n",
        "        logits, labels = eval_pred\n",
        "        print(\"✅ compute_metrics 호출됨\")\n",
        "        print(\"logits shape:\", np.shape(logits))    # 예: (1471, 4, 4)\n",
        "        print(\"labels shape:\", np.shape(labels))    # 예: (1471, 4) 이어야 함\n",
        "\n",
        "        preds = np.argmax(logits, axis=2)\n",
        "        sentence_accuracy = (preds == labels).mean()\n",
        "        full_order_accuracy = (preds == labels).all(axis=1).mean()\n",
        "\n",
        "        print(f\"🎯 sentence_acc: {sentence_accuracy:.4f}, full_order_acc: {full_order_accuracy:.4f}\")\n",
        "\n",
        "        return {\n",
        "            \"sentence_accuracy\": sentence_accuracy,\n",
        "            \"full_order_accuracy\": full_order_accuracy\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"❌ compute_metrics 내부 오류: {e}\")\n",
        "        return {}\n"
      ],
      "metadata": {
        "id": "JMJJi0ciqvyi",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-01T05:07:30.904627Z",
          "iopub.execute_input": "2025-06-01T05:07:30.904872Z",
          "iopub.status.idle": "2025-06-01T05:07:30.910515Z",
          "shell.execute_reply.started": "2025-06-01T05:07:30.904856Z",
          "shell.execute_reply": "2025-06-01T05:07:30.909820Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model = GlobalOrderModel(model_name=\"klue/roberta-large\")  # ✅ RoBERTa로 교체\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # ✅ GPU 사용 여부 확인\n",
        "model.to(device)  # ✅ 모델을 해당 디바이스로 이동\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "83f169fb379640bf86dbebafdcb8beee",
            "5582fbaf7b2c4454abad09f68a82ffd0",
            "83e3cba167974e7ab1d155f24bc931b8",
            "4c066b88aed74ab786bd11abc3efa77b",
            "869d964efd0244cb9121f42d66325542",
            "3c6a54e670684cbd8b105a8a094678e7",
            "3cd7d0f3436449fa9b861789ddae30bb",
            "ccc143d7eb824bde97a3f8b814691c0a",
            "2574c9e9e5c946dfaed6acc1e52cb907",
            "f4abc006a1434a0da24304d4a49d29bf",
            "f6691e7265e5472e8d3b9612f5cc2b94",
            "f3585241baf04490a9fc6ccf611c731a",
            "83e4b9a04e694a70be269f7f26eabc15",
            "e387edd818c34a57a7457782d3db3b2e",
            "9f3fdc17e5c64c0ca901dbb8914e5d74",
            "05d96bcb9e2144989bdfaf7b1cd6c8af",
            "82599d47451a4509a2fa181fb8d393ae",
            "c5605dc04126455abede39f423c2fcfc",
            "64ce0266992c4d178416dd3d9f6676f7",
            "1a415f83ccf54c40a5cffc579c9806c2",
            "b861f9f5cf6848a882a6a12d8b88b5b6",
            "37ff70ed35bd462883e18b993fe5b39e"
          ]
        },
        "id": "o2wujibZqvyj",
        "outputId": "b299fbae-af64-4517-fff8-8abd7d113c31",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-01T03:00:42.545661Z",
          "iopub.execute_input": "2025-06-01T03:00:42.545870Z",
          "iopub.status.idle": "2025-06-01T03:00:52.346277Z",
          "shell.execute_reply.started": "2025-06-01T03:00:42.545855Z",
          "shell.execute_reply": "2025-06-01T03:00:52.345672Z"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/547 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "83f169fb379640bf86dbebafdcb8beee"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.35G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f3585241baf04490a9fc6ccf611c731a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GlobalOrderModel(\n",
              "  (bert): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(32000, 1024, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 1024)\n",
              "      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-23): 24 x RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSdpaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): RobertaPooler(\n",
              "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Dropout(p=0.3, inplace=False)\n",
              "    (3): Linear(in_features=1024, out_features=16, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# ✅ RoBERTa 전용 tokenizer 사용\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"klue/roberta-large\")\n",
        "\n",
        "# 🔹 학습 데이터셋 생성\n",
        "train_dataset = GlobalOrderDataset(train_path, tokenizer, labels=train_labels)\n",
        "train_labels = make_labels(train_path)"
      ],
      "metadata": {
        "id": "9o3JPXvnqvyk",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-01T03:00:52.374478Z",
          "iopub.execute_input": "2025-06-01T03:00:52.374729Z",
          "iopub.status.idle": "2025-06-01T03:00:53.739122Z",
          "shell.execute_reply.started": "2025-06-01T03:00:52.374711Z",
          "shell.execute_reply": "2025-06-01T03:00:53.738539Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[0]"
      ],
      "metadata": {
        "id": "RPwjO-gFqvyk",
        "outputId": "d7ddc52f-38f2-4f6c-c209-e43c5f57052c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-01T03:00:53.739812Z",
          "iopub.execute_input": "2025-06-01T03:00:53.740094Z",
          "iopub.status.idle": "2025-06-01T03:00:53.755111Z",
          "shell.execute_reply.started": "2025-06-01T03:00:53.740069Z",
          "shell.execute_reply": "2025-06-01T03:00:53.754565Z"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([    0,     0, 18966,  3726,  2073,  4653,  3747,  2079,  5767,  2047,\n",
              "          2069,  1750,  2318,  5144,  2067,  2764,  1295,  1513,  2062,    18,\n",
              "             2,  3839,  2470,  4803,  2073,  7243,  2031,  2170,  2318,  4901,\n",
              "          2138,  3894,  2205,  2307,    16,  3772,  2125,  3844,  2138,  6627,\n",
              "          2205,  2259,   842,  5291,  2085,  1295,  1513,  2062,    18,     2,\n",
              "          3731, 11187, 18966,  4568,  2079,  4653,  4119,  2073,  4646, 19521,\n",
              "          4901,  2085,  1295,  1513,  2259,  3862,  3828,  2069,  4196,  2085,\n",
              "         10149,  2069, 16954,    18,     2,   544,  4653,  2259,  5131,  5391,\n",
              "          2183,  2470,  3809,  6233,  6965,  2496,  2051,  6251,  2079,  3662,\n",
              "          2047,  2069,  7848, 11187,  6202,  4538,    18,     2,     2,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1]),\n",
              " 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
              " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
              " 'labels': tensor([0, 2, 3, 1])}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "from transformers import AutoTokenizer, Trainer, TrainingArguments\n",
        "\n",
        "# ✅ RoBERTa tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"klue/roberta-large\")\n",
        "\n",
        "# 🔹 전체 라벨 생성\n",
        "labels = make_labels(train_path)\n",
        "\n",
        "# ✅ TrainingArguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./global_results\",\n",
        "    num_train_epochs=5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=64,\n",
        "    eval_strategy=\"no\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=100,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    load_best_model_at_end=False,\n",
        "    seed=42,\n",
        ")\n",
        "\n",
        "# ✅ Trainer 설정 (전체 학습용)\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=None,\n",
        "    compute_metrics=None,\n",
        ")\n"
      ],
      "metadata": {
        "id": "IZhH1DBDqvyk",
        "outputId": "171e15b1-18ac-4f92-bd5b-95c095bf6c0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-01T03:00:53.765191Z",
          "iopub.execute_input": "2025-06-01T03:00:53.765460Z",
          "iopub.status.idle": "2025-06-01T03:00:54.203884Z",
          "shell.execute_reply.started": "2025-06-01T03:00:53.765434Z",
          "shell.execute_reply": "2025-06-01T03:00:54.203347Z"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 학습 실행"
      ],
      "metadata": {
        "id": "lY8Lwbxlqvyl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "aK7jM5bgqvyl",
        "outputId": "2540010a-b02a-447e-da8b-2f6fe5fa88e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 831
        },
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-01T03:00:54.204528Z",
          "iopub.execute_input": "2025-06-01T03:00:54.204704Z",
          "iopub.status.idle": "2025-06-01T03:46:37.623567Z",
          "shell.execute_reply.started": "2025-06-01T03:00:54.204689Z",
          "shell.execute_reply": "2025-06-01T03:46:37.623046Z"
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2300' max='2300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2300/2300 1:22:57, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.376500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.286700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.027300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.834800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.671400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.602600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.578000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.543100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.529600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.459500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.398600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.379100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.335800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.306600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.230600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.211500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.192000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.172600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.130800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.081600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.082800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.081600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.075900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2300, training_loss=0.4603814475432686, metrics={'train_runtime': 4979.3022, 'train_samples_per_second': 7.382, 'train_steps_per_second': 0.462, 'total_flos': 0.0, 'train_loss': 0.4603814475432686, 'epoch': 5.0})"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "checkpoints = [\"checkpoint-368\", \"checkpoint-736\", \"checkpoint-1104\", \"checkpoint-1472\", \"checkpoint-1840\"]\n",
        "for ckpt in checkpoints:\n",
        "    shutil.rmtree(f\"/content/global_results/{ckpt}\", ignore_errors=True)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-01T03:46:37.624379Z",
          "iopub.execute_input": "2025-06-01T03:46:37.624610Z",
          "iopub.status.idle": "2025-06-01T03:46:40.223270Z",
          "shell.execute_reply.started": "2025-06-01T03:46:37.624593Z",
          "shell.execute_reply": "2025-06-01T03:46:40.222720Z"
        },
        "id": "NqBStvCEvlGq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ best checkpoint 기준으로 모델 저장\n",
        "save_path = \"/content/global_results/best_model\"\n",
        "\n",
        "trainer.save_model(save_path)\n",
        "tokenizer.save_pretrained(save_path)"
      ],
      "metadata": {
        "id": "Mt9_t0q0qvyl",
        "outputId": "b2888330-3a83-49b8-b007-e2042f1928a2",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-01T03:46:40.224017Z",
          "iopub.execute_input": "2025-06-01T03:46:40.224220Z",
          "iopub.status.idle": "2025-06-01T03:46:48.256575Z",
          "shell.execute_reply.started": "2025-06-01T03:46:40.224204Z",
          "shell.execute_reply": "2025-06-01T03:46:48.255831Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/global_results/best_model/tokenizer_config.json',\n",
              " '/content/global_results/best_model/special_tokens_map.json',\n",
              " '/content/global_results/best_model/vocab.txt',\n",
              " '/content/global_results/best_model/added_tokens.json',\n",
              " '/content/global_results/best_model/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 튜닝"
      ],
      "metadata": {
        "id": "k9zZk5Htqvym"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ 튜닝용 데이터 분리\n",
        "train_split_df, val_df = train_test_split(train_path, test_size=0.2, random_state=42)\n",
        "train_split_labels = make_labels(train_split_df)\n",
        "val_labels = make_labels(val_df)\n",
        "\n",
        "train_split_dataset = GlobalOrderDataset(train_split_df, tokenizer, labels=train_split_labels)\n",
        "val_dataset = GlobalOrderDataset(val_df, tokenizer, labels=val_labels)\n"
      ],
      "metadata": {
        "id": "8RJCDLtrMKCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "from scipy.stats import loguniform\n",
        "import numpy as np\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "eQKnoIitqvym",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-01T03:46:48.257394Z",
          "iopub.execute_input": "2025-06-01T03:46:48.257711Z",
          "iopub.status.idle": "2025-06-01T03:46:48.261445Z",
          "shell.execute_reply.started": "2025-06-01T03:46:48.257681Z",
          "shell.execute_reply": "2025-06-01T03:46:48.260669Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import shutil\n",
        "from scipy.stats import loguniform\n",
        "from transformers import AutoTokenizer, Trainer, TrainingArguments\n",
        "\n",
        "def run_global_tuning(train_split_dataset, val_dataset, tokenizer, n_trials=2):\n",
        "    results_path = './global_results/tuning_log.csv'\n",
        "    if os.path.exists(results_path):\n",
        "        results = pd.read_csv(results_path).to_dict(orient='records')\n",
        "        start_trial = len(results)\n",
        "    else:\n",
        "        results = []\n",
        "        start_trial = 0\n",
        "\n",
        "    for trial in range(start_trial, n_trials):\n",
        "        print(f\"\\n🎯 Trial {trial + 1} 시작\")\n",
        "        lr = float(loguniform.rvs(1.5e-5, 3.5e-5))\n",
        "        wd = float(loguniform.rvs(0.01, 0.07))\n",
        "        epochs = int(np.random.randint(9, 13))\n",
        "        batch_size = 16\n",
        "        total_steps = (len(train_split_dataset) // batch_size) * epochs\n",
        "        warmup = int(total_steps * 0.02)\n",
        "\n",
        "        args = TrainingArguments(\n",
        "            output_dir=f'./global_results/trial_{trial+1}',\n",
        "            learning_rate=lr,\n",
        "            weight_decay=wd,\n",
        "            warmup_steps=warmup,\n",
        "            per_device_train_batch_size=batch_size,\n",
        "            per_device_eval_batch_size=64,\n",
        "            num_train_epochs=epochs,\n",
        "            gradient_accumulation_steps=1,\n",
        "            lr_scheduler_type='linear',\n",
        "            logging_dir='./roberta_logs',\n",
        "            logging_steps=100,\n",
        "            save_strategy=\"epoch\",\n",
        "            save_total_limit=2,\n",
        "            eval_strategy='epoch',  # ✅ 평가 활성화\n",
        "            seed=42,\n",
        "            load_best_model_at_end=True,\n",
        "            metric_for_best_model='full_order_accuracy',  # ✅ 이 기준으로 best 선택\n",
        "            greater_is_better=True,\n",
        "            report_to='none',\n",
        "            fp16=True,\n",
        "            optim='adamw_torch_fused'\n",
        "        )\n",
        "\n",
        "        trainer = Trainer(\n",
        "            model=GlobalOrderModel(\"klue/roberta-large\"),\n",
        "            args=args,\n",
        "            train_dataset=train_split_dataset,\n",
        "            eval_dataset=val_dataset,\n",
        "            tokenizer=tokenizer,\n",
        "            compute_metrics=compute_metrics,  # ✅ 사용자 정의 메트릭\n",
        "            callbacks=[],\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            trainer.train()\n",
        "\n",
        "            # 최종 평가\n",
        "            eval_result = trainer.evaluate()\n",
        "            sentence_acc = eval_result.get(\"eval_sentence_accuracy\", None)\n",
        "            full_order_acc = eval_result.get(\"eval_full_order_accuracy\", None)\n",
        "            eval_loss = eval_result.get(\"eval_loss\", None)\n",
        "\n",
        "            save_path = f'./global_results/trial_{trial+1}/best_model'\n",
        "            try:\n",
        "                trainer.save_model(save_path)\n",
        "                tokenizer.save_pretrained(save_path)\n",
        "                model_saved = True\n",
        "            except Exception as e:\n",
        "                print(f\"⚠️ 모델 저장 실패: {e}\")\n",
        "                model_saved = False\n",
        "                save_path = \"FAILED\"\n",
        "\n",
        "            results.append({\n",
        "                'trial': trial + 1,\n",
        "                'learning_rate': lr,\n",
        "                'weight_decay': wd,\n",
        "                'warmup_steps': warmup,\n",
        "                'epochs': epochs,\n",
        "                'sentence_accuracy': sentence_acc,\n",
        "                'full_order_accuracy': full_order_acc,\n",
        "                'eval_loss': eval_loss,\n",
        "                'model_saved': model_saved,\n",
        "                'save_path': save_path\n",
        "            })\n",
        "            pd.DataFrame(results).to_csv(results_path, index=False)\n",
        "\n",
        "            # checkpoint 정리\n",
        "            output_dir = f'./global_results/trial_{trial+1}'\n",
        "            for subdir in os.listdir(output_dir):\n",
        "                if subdir.startswith(\"checkpoint\"):\n",
        "                    shutil.rmtree(os.path.join(output_dir, subdir), ignore_errors=True)\n",
        "\n",
        "            print(f\"✅ Trial {trial+1} 완료 | 저장 경로: {save_path}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"⛔ Trial {trial+1} 중 오류 발생: {e}\")\n",
        "            break\n",
        "\n",
        "    print(\"\\n🏆 상위 Trial:\")\n",
        "    top_trials = pd.DataFrame(results).sort_values(by=\"full_order_accuracy\", ascending=False).head(1)\n",
        "    print(top_trials)\n",
        "    return top_trials\n"
      ],
      "metadata": {
        "id": "P3ib1CWaqvym",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-01T05:08:09.402541Z",
          "iopub.execute_input": "2025-06-01T05:08:09.403316Z",
          "iopub.status.idle": "2025-06-01T05:08:09.415372Z",
          "shell.execute_reply.started": "2025-06-01T05:08:09.403290Z",
          "shell.execute_reply": "2025-06-01T05:08:09.414704Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "top_trials = run_global_tuning(train_split_dataset, val_dataset, tokenizer, n_trials=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5cHtmtQzPds5",
        "outputId": "523d3eb8-7665-4d0b-dd45-d272e558851a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🎯 Trial 1 시작\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-31-a3c58d75626e>:51: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4048' max='4048' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4048/4048 44:19, Epoch 11/11]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Sentence Accuracy</th>\n",
              "      <th>Full Order Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.179400</td>\n",
              "      <td>1.072099</td>\n",
              "      <td>0.443576</td>\n",
              "      <td>0.028552</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.653900</td>\n",
              "      <td>0.462166</td>\n",
              "      <td>0.844494</td>\n",
              "      <td>0.625425</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.279200</td>\n",
              "      <td>0.322806</td>\n",
              "      <td>0.897689</td>\n",
              "      <td>0.789939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.177200</td>\n",
              "      <td>0.309631</td>\n",
              "      <td>0.905676</td>\n",
              "      <td>0.808973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.098400</td>\n",
              "      <td>0.344414</td>\n",
              "      <td>0.917233</td>\n",
              "      <td>0.835486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.039600</td>\n",
              "      <td>0.402695</td>\n",
              "      <td>0.918423</td>\n",
              "      <td>0.836166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.017600</td>\n",
              "      <td>0.431295</td>\n",
              "      <td>0.919782</td>\n",
              "      <td>0.842284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.014500</td>\n",
              "      <td>0.431568</td>\n",
              "      <td>0.923861</td>\n",
              "      <td>0.845683</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.007000</td>\n",
              "      <td>0.447171</td>\n",
              "      <td>0.926241</td>\n",
              "      <td>0.851801</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.006700</td>\n",
              "      <td>0.466715</td>\n",
              "      <td>0.926751</td>\n",
              "      <td>0.852481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.006500</td>\n",
              "      <td>0.471715</td>\n",
              "      <td>0.926581</td>\n",
              "      <td>0.853161</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ compute_metrics 호출됨\n",
            "logits shape: (1471, 4, 4)\n",
            "labels shape: (1471, 4)\n",
            "🎯 sentence_acc: 0.4436, full_order_acc: 0.0286\n",
            "✅ compute_metrics 호출됨\n",
            "logits shape: (1471, 4, 4)\n",
            "labels shape: (1471, 4)\n",
            "🎯 sentence_acc: 0.8445, full_order_acc: 0.6254\n",
            "✅ compute_metrics 호출됨\n",
            "logits shape: (1471, 4, 4)\n",
            "labels shape: (1471, 4)\n",
            "🎯 sentence_acc: 0.8977, full_order_acc: 0.7899\n",
            "✅ compute_metrics 호출됨\n",
            "logits shape: (1471, 4, 4)\n",
            "labels shape: (1471, 4)\n",
            "🎯 sentence_acc: 0.9057, full_order_acc: 0.8090\n",
            "✅ compute_metrics 호출됨\n",
            "logits shape: (1471, 4, 4)\n",
            "labels shape: (1471, 4)\n",
            "🎯 sentence_acc: 0.9172, full_order_acc: 0.8355\n",
            "✅ compute_metrics 호출됨\n",
            "logits shape: (1471, 4, 4)\n",
            "labels shape: (1471, 4)\n",
            "🎯 sentence_acc: 0.9184, full_order_acc: 0.8362\n",
            "✅ compute_metrics 호출됨\n",
            "logits shape: (1471, 4, 4)\n",
            "labels shape: (1471, 4)\n",
            "🎯 sentence_acc: 0.9198, full_order_acc: 0.8423\n",
            "✅ compute_metrics 호출됨\n",
            "logits shape: (1471, 4, 4)\n",
            "labels shape: (1471, 4)\n",
            "🎯 sentence_acc: 0.9239, full_order_acc: 0.8457\n",
            "✅ compute_metrics 호출됨\n",
            "logits shape: (1471, 4, 4)\n",
            "labels shape: (1471, 4)\n",
            "🎯 sentence_acc: 0.9262, full_order_acc: 0.8518\n",
            "✅ compute_metrics 호출됨\n",
            "logits shape: (1471, 4, 4)\n",
            "labels shape: (1471, 4)\n",
            "🎯 sentence_acc: 0.9268, full_order_acc: 0.8525\n",
            "✅ compute_metrics 호출됨\n",
            "logits shape: (1471, 4, 4)\n",
            "labels shape: (1471, 4)\n",
            "🎯 sentence_acc: 0.9266, full_order_acc: 0.8532\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [23/23 00:12]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ compute_metrics 호출됨\n",
            "logits shape: (1471, 4, 4)\n",
            "labels shape: (1471, 4)\n",
            "🎯 sentence_acc: 0.9266, full_order_acc: 0.8532\n",
            "✅ Trial 1 완료 | 저장 경로: ./global_results/trial_1/best_model\n",
            "\n",
            "🎯 Trial 2 시작\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-31-a3c58d75626e>:51: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='106' max='4048' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 106/4048 01:01 < 38:39, 1.70 it/s, Epoch 0.29/11]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# ✅ 튜닝 로그 불러오기\n",
        "df = pd.read_csv(\"./global_results/tuning_log.csv\")\n",
        "\n",
        "# ✅ 모델 저장된 trial만 남기기\n",
        "df = df[df[\"model_saved\"] == True]\n",
        "\n",
        "# ✅ 평가 결과가 있는 경우: full_order_accuracy 기준 선택, 없으면 trial 번호 기준\n",
        "if \"full_order_accuracy\" in df.columns and df[\"full_order_accuracy\"].notna().any():\n",
        "    top_trial = df.sort_values(\"full_order_accuracy\", ascending=False).iloc[0]\n",
        "else:\n",
        "    top_trial = df.sort_values(\"trial\", ascending=True).iloc[0]  # fallback\n",
        "\n",
        "# ✅ 경로 확인\n",
        "best_model_path = top_trial[\"save_path\"]\n",
        "print(f\"🏆 선택된 Best Model 경로: {best_model_path}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-01T06:34:21.010157Z",
          "iopub.execute_input": "2025-06-01T06:34:21.010657Z",
          "iopub.status.idle": "2025-06-01T07:48:58.152284Z",
          "shell.execute_reply.started": "2025-06-01T06:34:21.010636Z",
          "shell.execute_reply": "2025-06-01T07:48:58.151572Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 894
        },
        "id": "K60egL2QvlGs",
        "outputId": "fbc0ed35-ad77-480f-cb67-9f51a2abbe48"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: './global_results/tuning_log.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-77b94512d330>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# ✅ 튜닝 로그 불러오기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./global_results/tuning_log.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# ✅ 모델 저장된 trial만 남기기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './global_results/tuning_log.csv'"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ 실제 폴더 존재하는지 확인 (예시로 trial_2)\n",
        "print(os.listdir(best_model_path))\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-01T07:58:04.703362Z",
          "iopub.execute_input": "2025-06-01T07:58:04.703622Z",
          "iopub.status.idle": "2025-06-01T07:58:04.708442Z",
          "shell.execute_reply.started": "2025-06-01T07:58:04.703604Z",
          "shell.execute_reply": "2025-06-01T07:58:04.707904Z"
        },
        "id": "EHbsZjeyvlGt"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ 모델 로드\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = GlobalOrderModel(\"klue/roberta-large\")\n",
        "\n",
        "# safetensors 파일 로드\n",
        "state_dict = load_file(f\"{best_model_path}/model.safetensors\")\n",
        "model.load_state_dict(state_dict)\n",
        "model.to(device)\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "KakFqVkwqvyn",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-01T08:01:38.654131Z",
          "iopub.execute_input": "2025-06-01T08:01:38.654688Z",
          "iopub.status.idle": "2025-06-01T08:01:49.386969Z",
          "shell.execute_reply.started": "2025-06-01T08:01:38.654666Z",
          "shell.execute_reply": "2025-06-01T08:01:49.386247Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "final_model_dir = \"./global_results/best_model_custom\"\n",
        "shutil.copytree(best_model_path, final_model_dir, dirs_exist_ok=True)\n",
        "print(f\"📦 최종 best model 저장됨: {final_model_dir}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-01T08:02:23.003011Z",
          "iopub.execute_input": "2025-06-01T08:02:23.003290Z",
          "iopub.status.idle": "2025-06-01T08:02:23.982289Z",
          "shell.execute_reply.started": "2025-06-01T08:02:23.003270Z",
          "shell.execute_reply": "2025-06-01T08:02:23.981645Z"
        },
        "id": "_TCclSrLvlGu"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 추론"
      ],
      "metadata": {
        "id": "Gr3bPsfdqvyn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 🔹 전체 학습 데이터셋 구성\n",
        "train_labels = make_labels(train_path)\n",
        "train_dataset = GlobalOrderDataset(train_path, tokenizer, labels=train_labels)\n",
        "\n",
        "# 🔹 튜닝 결과에서 best 설정 추출\n",
        "# (예: top_trial에서 learning_rate, weight_decay 등 가져오기)\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"./global_results/best_final\",\n",
        "    learning_rate=top_trial['learning_rate'],\n",
        "    weight_decay=top_trial['weight_decay'],\n",
        "    warmup_steps=int(top_trial['warmup_steps']),\n",
        "    per_device_train_batch_size=16,\n",
        "    num_train_epochs=int(top_trial['epochs']),\n",
        "    logging_dir='./retrain_logs',\n",
        "    save_strategy=\"no\",  # ❌ 저장은 수동으로\n",
        "    evaluation_strategy=\"no\",\n",
        "    report_to='none',\n",
        "    fp16=True,\n",
        "    optim=\"adamw_torch_fused\"\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=GlobalOrderModel(\"klue/roberta-large\"),\n",
        "    args=args,\n",
        "    train_dataset=train_dataset,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "# 🔹 재학습\n",
        "trainer.train()\n",
        "\n",
        "# 🔹 최종 모델 저장\n",
        "trainer.save_model(\"./global_results/final_model\")\n",
        "tokenizer.save_pretrained(\"./global_results/final_model\")\n"
      ],
      "metadata": {
        "id": "rq0TN0gkN9lL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ 모델 클래스 직접 정의 (model.py 없이도 OK)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoModel\n",
        "\n",
        "class GlobalOrderModel(nn.Module):\n",
        "    def __init__(self, model_name='klue/roberta-large'):\n",
        "        super().__init__()\n",
        "        self.bert = AutoModel.from_pretrained(model_name)\n",
        "        hidden_size = self.bert.config.hidden_size\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_size, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(1024, 4 * 4)\n",
        "        )\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled = outputs.last_hidden_state[:, 0]\n",
        "        logits = self.classifier(pooled)\n",
        "        if labels is not None:\n",
        "            loss_fn = nn.CrossEntropyLoss()\n",
        "            loss = loss_fn(logits.view(-1, 4), labels.view(-1))\n",
        "            return {\"loss\": loss, \"logits\": logits.view(-1, 4, 4)}\n",
        "        else:\n",
        "            return {\"logits\": logits.view(-1, 4, 4)}\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-01T08:05:53.466448Z",
          "iopub.execute_input": "2025-06-01T08:05:53.467139Z",
          "iopub.status.idle": "2025-06-01T08:05:53.473162Z",
          "shell.execute_reply.started": "2025-06-01T08:05:53.467114Z",
          "shell.execute_reply": "2025-06-01T08:05:53.472399Z"
        },
        "id": "6yHsT_LQvlGv"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from safetensors.torch import load_file\n",
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "best_model_path = \"./global_results/best_model_custom\"  # ← 경로 꼭 이걸로 맞춰주세요\n",
        "\n",
        "model = GlobalOrderModel(\"klue/roberta-large\")\n",
        "state_dict = load_file(f\"{best_model_path}/model.safetensors\")\n",
        "model.load_state_dict(state_dict)\n",
        "model.to(device)\n",
        "model.eval()\n"
      ],
      "metadata": {
        "id": "Ts-9bs7Hqvyn",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-01T08:06:47.999560Z",
          "iopub.execute_input": "2025-06-01T08:06:48.000123Z",
          "iopub.status.idle": "2025-06-01T08:06:49.700655Z",
          "shell.execute_reply.started": "2025-06-01T08:06:48.000100Z",
          "shell.execute_reply": "2025-06-01T08:06:49.700032Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ 직접 정의한 Dataset 클래스\n",
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "\n",
        "class GlobalOrderDataset(Dataset):\n",
        "    def __init__(self, df, tokenizer, labels=None, max_length=256):\n",
        "        self.sentences = df[[f'sentence_{i}' for i in range(4)]].values\n",
        "        self.tokenizer = tokenizer\n",
        "        self.labels = labels\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sentences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sents = self.sentences[idx]\n",
        "        text = '[CLS] ' + ' [SEP] '.join(sents) + ' [SEP]'\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        item = {k: v.squeeze(0) for k, v in encoding.items()}\n",
        "        if self.labels is not None:\n",
        "            item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        return item\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-01T08:08:33.785089Z",
          "iopub.execute_input": "2025-06-01T08:08:33.785750Z",
          "iopub.status.idle": "2025-06-01T08:08:33.791747Z",
          "shell.execute_reply.started": "2025-06-01T08:08:33.785726Z",
          "shell.execute_reply": "2025-06-01T08:08:33.790896Z"
        },
        "id": "rih_pCeYvlGv"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# inference.py\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader\n",
        "def predict(model, test_df, tokenizer, device, batch_size=32):\n",
        "    test_dataset = GlobalOrderDataset(test_df, tokenizer, labels=None)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            logits = model(input_ids, attention_mask)['logits']  # ✅ dict에서 'logits' 꺼냄\n",
        "            preds = logits.argmax(-1).cpu().numpy()\n",
        "            all_preds.append(preds)\n",
        "    all_preds = np.concatenate(all_preds, axis=0)\n",
        "    # [문장0은 몇 번째, ...] → [answer_0, answer_1, ...]로 역변환\n",
        "    answers = []\n",
        "    for row in all_preds:\n",
        "        answer = [0]*4\n",
        "        for sent_idx, pos in enumerate(row):\n",
        "            answer[pos] = sent_idx\n",
        "        answers.append(answer)\n",
        "    return np.array(answers)\n",
        "\n",
        "def save_submission(test_df, answers, submission_path, output_path):\n",
        "    sub = pd.read_csv(submission_path)\n",
        "    for i in range(4):\n",
        "        sub[f'answer_{i}'] = answers[:, i]\n",
        "    sub.to_csv(output_path, index=False)\n"
      ],
      "metadata": {
        "id": "cnMgu5Ktqvyn",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-01T08:17:52.070370Z",
          "iopub.execute_input": "2025-06-01T08:17:52.071041Z",
          "iopub.status.idle": "2025-06-01T08:17:52.078354Z",
          "shell.execute_reply.started": "2025-06-01T08:17:52.071008Z",
          "shell.execute_reply": "2025-06-01T08:17:52.077612Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 예측 및 저장"
      ],
      "metadata": {
        "id": "CZbjmSB1qvyn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 예측 수행\n",
        "answers = predict(\n",
        "    model=model,\n",
        "    test_df=test_df,\n",
        "    tokenizer=tokenizer,\n",
        "    device=device,\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "# 제출 파일 저장\n",
        "save_submission(\n",
        "    test_df=test_df,\n",
        "    answers=answers,\n",
        "    submission_path=\"/content/sample_submission.csv\",\n",
        "    output_path=\"/content/submission.csv\"\n",
        ")\n",
        "\n",
        "print(\"✅ submission.csv 저장 완료\")"
      ],
      "metadata": {
        "id": "ETwtfIxcqvyo",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-01T08:17:54.490618Z",
          "iopub.execute_input": "2025-06-01T08:17:54.491310Z",
          "iopub.status.idle": "2025-06-01T08:18:37.884347Z",
          "shell.execute_reply.started": "2025-06-01T08:17:54.491285Z",
          "shell.execute_reply": "2025-06-01T08:18:37.883567Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "1차 결과: 0.82134\n",
        "# 2차 코드 점검"
      ],
      "metadata": {
        "id": "pFTz1t85vlGx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 혼동행렬 분석 결과\n",
        "- ✅ 결과 해석 (요약)\n",
        "정답 → 예측\t가장 많이 헷갈린 조합\n",
        "0 → 1\t53건 → 문장 0을 1번 위치로 착각\n",
        "1 → 3\t46건\n",
        "2 → 3\t50건\n",
        "3 → 2\t51건\n",
        "\n",
        "  🔍 구체적 해석\n",
        "대각선 값이 높을수록 (1350 이상) → 정확히 예측한 경우.\n",
        "\n",
        "대각선 바깥 값은 오답인데, 특히 다음 케이스가 문제:\n",
        "\n",
        "문장 2와 문장 3은 서로 자주 헷갈림 (2→3: 50건, 3→2: 51건)\n",
        "\n",
        "문장 0은 거의 안 헷갈리는데도 0→1: 53건 존재함\n",
        "\n",
        "후반 문장(2, 3) 사이의 연결성이 약하거나, 모델이 전개 흐름을 파악하지 못하고 있음\n",
        "\n",
        "문장 0 → 1 착각은 시작 문장 판단 근거 부족을 의미\n",
        "\n",
        "ex. [SEP]으로만 문장 구분했을 때, 첫 문장만의 특성 학습이 어렵다면 생김\n",
        "\n",
        "\n",
        "### 개선 아이디어\n",
        "| 문제           | 해결 방안                                                            |\n",
        "| ------------ | ---------------------------------------------------------------- |\n",
        "| 문장 0/1 구분 애매 | 문장 시작을 명확히 학습시키기 위한 **문장 위치 임베딩 추가**                             |\n",
        "| 문장 2/3 혼동    | Pairwise loss 도입 or 후반 문장 강조 학습 (e.g. position-aware classifier) |\n",
        "| 전체 미세 성능 향상  | 앙상블 (Global + Pairwise), 또는 warmup 증가, 학습 에폭 증가                  |\n",
        "\n",
        "*위치 사용 모델*\n",
        "01, 12\t기존 Global 예측 유지\n",
        "2~3\tpairwise 모델로 sent_2 vs sent_3 우선순위 재결정\n"
      ],
      "metadata": {
        "id": "_QhQL0xOvlG9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zmMDnnpovlG9"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "8L8kxlRsvlG9"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}
{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "a4hMUXbK0UIc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import shutil\n",
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-01T03:00:14.753640Z",
          "iopub.status.busy": "2025-06-01T03:00:14.753407Z",
          "iopub.status.idle": "2025-06-01T03:00:42.075447Z",
          "shell.execute_reply": "2025-06-01T03:00:42.074853Z",
          "shell.execute_reply.started": "2025-06-01T03:00:14.753623Z"
        },
        "id": "7FIQKoH2qvyZ",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.stats import kendalltau, spearmanr\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModel,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    EarlyStoppingCallback\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-06-01T08:15:35.606019Z",
          "iopub.status.busy": "2025-06-01T08:15:35.605388Z",
          "iopub.status.idle": "2025-06-01T08:15:35.715969Z",
          "shell.execute_reply": "2025-06-01T08:15:35.715222Z",
          "shell.execute_reply.started": "2025-06-01T08:15:35.605996Z"
        },
        "id": "B8Ezv7ZKqvya",
        "outputId": "6e0f8ac8-c01d-49c0-f7df-c22b2ee4601e",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "PT30-RU7vslh"
      },
      "outputs": [],
      "source": [
        "# %cd /content/drive/MyDrive/25-1í•™ê¸°/AIë¥¼ ìœ„í•œ ë”¥ëŸ¬ë‹/team_project\n",
        "# base_path = \"/content/drive/MyDrive/25-1í•™ê¸°/AIë¥¼ ìœ„í•œ ë”¥ëŸ¬ë‹/team_project\"\n",
        "base_path = '.'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Abf6t3Zwvtv9"
      },
      "outputs": [],
      "source": [
        "# ë°ì´í„° ë¡œë“œ\n",
        "train_path = pd.read_csv(f'{base_path}/data/train_extended.csv')\n",
        "test_path = pd.read_csv(f'{base_path}/data/test.csv')\n",
        "submission_path = pd.read_csv(f'{base_path}/data/sample_submission.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "zuOt9p9Wa1ov"
      },
      "outputs": [],
      "source": [
        "# í…ìŠ¤íŠ¸ ì •ì œ\n",
        "def clean_text(text):\n",
        "  # íŠ¹ìˆ˜ë¬¸ì ì œê±°\n",
        "  text = re.sub(r'[^\\w\\s]', '', text)\n",
        "  # ì†Œë¬¸ì ë³€í™˜: í•œê¸€ì—ëŠ” ë¬´ì˜ë¯¸\n",
        "  text = text.lower()\n",
        "  # ë¶ˆí•„ìš”í•œ ê³µë°± ì œê±°\n",
        "  text = ' '.join(text.split())\n",
        "  return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "sOkdMtZla3gk"
      },
      "outputs": [],
      "source": [
        "# í…ìŠ¤íŠ¸ ì •ì œ\n",
        "for i in range(4):\n",
        "    train_path[f'sentence_{i}'] = train_path[f'sentence_{i}'].apply(clean_text)\n",
        "    test_path[f'sentence_{i}'] = test_path[f'sentence_{i}'].apply(clean_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-01T03:00:42.475540Z",
          "iopub.status.busy": "2025-06-01T03:00:42.475322Z",
          "iopub.status.idle": "2025-06-01T03:00:42.493164Z",
          "shell.execute_reply": "2025-06-01T03:00:42.492316Z",
          "shell.execute_reply.started": "2025-06-01T03:00:42.475523Z"
        },
        "id": "gnF7yb6oqvyc",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def load_data(train_path, test_path):\n",
        "    train = pd.read_csv(train_path)\n",
        "    test = pd.read_csv(test_path)\n",
        "    return train, test\n",
        "\n",
        "def make_labels(df):\n",
        "    # answer_0 ~ answer_3 â†’ [ë¬¸ì¥0ì€ ëª‡ ë²ˆì§¸, ë¬¸ì¥1ì€ ëª‡ ë²ˆì§¸, ...]\n",
        "    answers = df[[f'answer_{i}' for i in range(4)]].values\n",
        "    labels = []\n",
        "    for row in answers:\n",
        "        label = [0]*4\n",
        "        for pos, sent_idx in enumerate(row):\n",
        "            label[sent_idx] = pos\n",
        "        labels.append(label)\n",
        "    return np.array(labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ëª¨ë¸ ì •ì˜ ë° í•™ìŠµ ì¤€ë¹„"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAdqOCQFqvyd"
      },
      "source": [
        "## Dataset í´ë˜ìŠ¤\n",
        " 4ê°œì˜ ë¬¸ì¥ì„ [SEP]ë¡œ ë¬¶ì–´ì„œ BERTì— ë„£ì„ ìˆ˜ ìˆê²Œ ë°”ê¿”ì¤Œ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-01T03:00:42.494067Z",
          "iopub.status.busy": "2025-06-01T03:00:42.493798Z",
          "iopub.status.idle": "2025-06-01T03:00:42.509629Z",
          "shell.execute_reply": "2025-06-01T03:00:42.509047Z",
          "shell.execute_reply.started": "2025-06-01T03:00:42.494050Z"
        },
        "id": "OnATscUgqvyg",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# ë°ì´í„°ì…‹ í´ë˜ìŠ¤\n",
        "class GlobalOrderDataset(Dataset):\n",
        "    def __init__(self, df, tokenizer, labels=None, max_length=128):\n",
        "        self.sentences = df[[f'sentence_{i}' for i in range(4)]].values\n",
        "        self.tokenizer = tokenizer\n",
        "        self.labels = labels\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sentences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sents = self.sentences[idx]\n",
        "        text = '[CLS] ' + ' [SEP] '.join(sents) + ' [SEP]'\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        item = {k: v.squeeze(0) for k, v in encoding.items()}\n",
        "\n",
        "        # labelsê°€ Noneì´ ì•„ë‹ ë•Œë§Œ labels ì¶”ê°€\n",
        "        if self.labels is not None:\n",
        "            item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "\n",
        "        return item"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_pTePS6qvyh"
      },
      "source": [
        "## Model í´ë˜ìŠ¤\n",
        "- AutoModel (ì˜ˆ: Roberta) ì‚¬ìš©\n",
        "- ë¬¸ì¥ 4ê°œë¥¼ ë„£ì—ˆì„ ë•Œ ê·¸ ìˆœì„œë¥¼ ì˜ˆì¸¡\n",
        "- ì¶œë ¥ì€ [batch, 4, 4] í¬ê¸°ì˜ í–‰ë ¬ â†’ ê° ë¬¸ì¥ì´ ì–´ë–¤ ìœ„ì¹˜ì— ìˆì–´ì•¼ í•˜ëŠ”ì§€ ì˜ˆì¸¡"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "4i-OjUv3nbvx"
      },
      "outputs": [],
      "source": [
        "class GlobalOrderModel(nn.Module):\n",
        "    def __init__(self, model_name='klue/roberta-large'):\n",
        "        super().__init__()\n",
        "        self.bert = AutoModel.from_pretrained(model_name)\n",
        "        hidden_size = self.bert.config.hidden_size\n",
        "\n",
        "        # BERT ëŒ€ë¶€ë¶„ ë™ê²° (ê³¼ì í•© ë°©ì§€)\n",
        "        for param in self.bert.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # ë§ˆì§€ë§‰ 6ê°œ ë ˆì´ì–´ë§Œ fine-tuning\n",
        "        for layer in self.bert.encoder.layer[-6:]:\n",
        "            for param in layer.parameters():\n",
        "                param.requires_grad = True\n",
        "\n",
        "        # ë‹¨ìˆœí•œ ë¶„ë¥˜ê¸° (ê³¼ì í•© ë°©ì§€)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_size, 512),\n",
        "            nn.LayerNorm(512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.4),\n",
        "\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LayerNorm(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.4),\n",
        "\n",
        "            nn.Linear(256, 4 * 4)\n",
        "        )\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "        # BERT ì¸ì½”ë”©\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "        # [CLS] í† í°ì„ ì‚¬ìš©\n",
        "        pooled = outputs.last_hidden_state[:, 0]\n",
        "\n",
        "        # ë¶„ë¥˜\n",
        "        logits = self.classifier(pooled)\n",
        "\n",
        "        if labels is not None:\n",
        "            loss_fn = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "            loss = loss_fn(logits.view(-1, 4), labels.view(-1))\n",
        "            return {\"loss\": loss, \"logits\": logits.view(-1, 4, 4)}\n",
        "        else:\n",
        "            return {\"logits\": logits.view(-1, 4, 4)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-01T05:07:30.904872Z",
          "iopub.status.busy": "2025-06-01T05:07:30.904627Z",
          "iopub.status.idle": "2025-06-01T05:07:30.910515Z",
          "shell.execute_reply": "2025-06-01T05:07:30.909820Z",
          "shell.execute_reply.started": "2025-06-01T05:07:30.904856Z"
        },
        "id": "JMJJi0ciqvyi",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    try:\n",
        "        logits, labels = eval_pred\n",
        "        preds = np.argmax(logits, axis=2)\n",
        "\n",
        "        # 1. ì „ì²´ ìˆœì„œ ì •í™•ë„ (4ê°œ ë¬¸ì¥ì´ ëª¨ë‘ ì˜¬ë°”ë¥¸ ìˆœì„œ)\n",
        "        full_order_accuracy = (preds == labels).all(axis=1).mean()\n",
        "\n",
        "        # 2. ê°œë³„ ë¬¸ì¥ ìœ„ì¹˜ ì •í™•ë„\n",
        "        sentence_accuracy = (preds == labels).mean()\n",
        "\n",
        "        # 3. Kendall's tau\n",
        "        tau_scores = []\n",
        "        for pred, label in zip(preds, labels):\n",
        "            try:\n",
        "                tau, _ = kendalltau(pred, label)\n",
        "                tau_scores.append(tau if not np.isnan(tau) else 0.0)\n",
        "            except:\n",
        "                tau_scores.append(0.0)\n",
        "        avg_tau = np.mean(tau_scores)\n",
        "\n",
        "        # 4. Spearman's rho\n",
        "        rho_scores = []\n",
        "        for pred, label in zip(preds, labels):\n",
        "            try:\n",
        "                rho, _ = spearmanr(pred, label)\n",
        "                rho_scores.append(rho if not np.isnan(rho) else 0.0)\n",
        "            except:\n",
        "                rho_scores.append(0.0)\n",
        "        avg_rho = np.mean(rho_scores)\n",
        "\n",
        "        # # 5. Position-wise accuracy\n",
        "        # position_accuracies = []\n",
        "        # for pos in range(4):\n",
        "        #     correct_pos = sum(1 for p, t in zip(preds, labels) if p[pos] == t[pos])\n",
        "        #     position_accuracies.append(correct_pos / len(labels))\n",
        "\n",
        "        # # 6. Inversion accuracy\n",
        "        # def count_inversions(pred, label):\n",
        "        #     inversions = 0\n",
        "        #     n = len(pred)\n",
        "        #     for i in range(n):\n",
        "        #         for j in range(i+1, n):\n",
        "        #             if (pred[i] < pred[j] and label[i] > label[j]) or \\\n",
        "        #                (pred[i] > pred[j] and label[i] < label[j]):\n",
        "        #                 inversions += 1\n",
        "        #     return inversions\n",
        "\n",
        "        # max_inversions = 6  # 4ê°œ ë¬¸ì¥ì˜ ìµœëŒ€ ë’¤ë°”ë€œ ê°œìˆ˜: C(4,2) = 6\n",
        "        # inversion_scores = []\n",
        "        # for pred, label in zip(preds, labels):\n",
        "        #     inv_count = count_inversions(pred, label)\n",
        "        #     accuracy = 1 - (inv_count / max_inversions)\n",
        "        #     inversion_scores.append(accuracy)\n",
        "        # inversion_accuracy = np.mean(inversion_scores)\n",
        "\n",
        "        # 5. Adjacent Pair Accuracy (ì¸ì ‘ ìŒ ì •í™•ë„)\n",
        "        adjacent_correct = 0\n",
        "        total_adjacent = 0\n",
        "\n",
        "        for i in range(0, len(pred), 6):\n",
        "            if i + 6 > len(pred):\n",
        "                break\n",
        "\n",
        "            group_preds = pred[i:i+6]\n",
        "            group_labels = labels[i:i+6]\n",
        "\n",
        "            # ì¸ì ‘ ìŒë§Œ ì¶”ì¶œ (0-1, 1-2, 2-3) - ì¸ë±ìŠ¤ ìˆ˜ì •\n",
        "            if len(group_preds) >= 6:\n",
        "                adjacent_preds = [group_preds[0], group_preds[2], group_preds[4]]\n",
        "                adjacent_labels = [group_labels[0], group_labels[2], group_labels[4]]\n",
        "\n",
        "                for pred, label in zip(adjacent_preds, adjacent_labels):\n",
        "                    if pred == label:\n",
        "                        adjacent_correct += 1\n",
        "                    total_adjacent += 1\n",
        "\n",
        "        adjacent_accuracy = adjacent_correct / total_adjacent if total_adjacent > 0 else 0.0\n",
        "\n",
        "        # 6. Long-range Pair Accuracy (ì›ê±°ë¦¬ ìŒ ì •í™•ë„)\n",
        "        long_range_correct = 0\n",
        "        total_long_range = 0\n",
        "\n",
        "        for i in range(0, len(pred), 6):\n",
        "            if i + 6 > len(pred):\n",
        "                break\n",
        "\n",
        "            group_preds = pred[i:i+6]\n",
        "            group_labels = labels[i:i+6]\n",
        "\n",
        "            # ì›ê±°ë¦¬ ìŒ ì¶”ì¶œ (0-2, 0-3, 1-3) - ì¸ë±ìŠ¤ ìˆ˜ì •\n",
        "            if len(group_preds) >= 6:\n",
        "                long_range_preds = [group_preds[1], group_preds[3], group_preds[5]]\n",
        "                long_range_labels = [group_labels[1], group_labels[3], group_labels[5]]\n",
        "\n",
        "                for pred, label in zip(long_range_preds, long_range_labels):\n",
        "                    if pred == label:\n",
        "                        long_range_correct += 1\n",
        "                    total_long_range += 1\n",
        "\n",
        "        long_range_accuracy = long_range_correct / total_long_range if total_long_range > 0 else 0.0\n",
        "\n",
        "        return {\n",
        "            \"full_order_accuracy\": full_order_accuracy,\n",
        "            \"sentence_accuracy\": sentence_accuracy,\n",
        "            \"kendall_tau\": avg_tau,\n",
        "            \"spearman_rho\": avg_rho,\n",
        "            # \"position_accuracies\": position_accuracies,\n",
        "            # \"inversion_accuracy\": inversion_accuracy,\n",
        "            \"adjacent_pair_accuracy\": adjacent_accuracy,\n",
        "            \"long_range_pair_accuracy\": long_range_accuracy\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ compute_metrics ë‚´ë¶€ ì˜¤ë¥˜: {e}\")\n",
        "        return {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "collapsed": true,
        "id": "UY7kZT-fiV5-"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d37566184d424067b48e7c49d988e6c1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/425 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "157d3be8db814a19b59f9d8bae7a3802",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/445M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1fd93c86c3ec485a8f3e8279ee65f3d6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/289 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b51f1977a2e3496392e4f8b3abc9bd5a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "78d23ff62f2448bf8b3f410c2a76836e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1fbe854aec07492195fe2a91c328bb64",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model_name = \"klue/bert-base\"\n",
        "\n",
        "model = GlobalOrderModel(model_name=model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## í•™ìŠµ ì¤€ë¹„"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "YXffWcWwiV5-"
      },
      "outputs": [],
      "source": [
        "# train/val ë¶„ë¦¬ (20% â†’ ê²€ì¦ì— ì‚¬ìš©)\n",
        "train_df_split, val_df = train_test_split(train_path, test_size=0.2, random_state=42)\n",
        "\n",
        "# ë¼ë²¨ ìƒì„±\n",
        "train_labels = make_labels(train_df_split)\n",
        "val_labels = make_labels(val_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "drOFkp3IiV5-"
      },
      "outputs": [],
      "source": [
        "# í•™ìŠµ ë°ì´í„°ì…‹ ìƒì„±\n",
        "train_dataset = GlobalOrderDataset(train_df_split, tokenizer, labels=train_labels)\n",
        "val_dataset = GlobalOrderDataset(val_df, tokenizer, labels=val_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kcJ1HwniV5_",
        "outputId": "3e39d668-20a6-4df2-c3eb-c4588c7bee5f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        }
      ],
      "source": [
        "# TrainingArguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./bert_results\",\n",
        "    num_train_epochs=5,\n",
        "    learning_rate=3e-5,\n",
        "    per_device_train_batch_size=64,\n",
        "    per_device_eval_batch_size=128,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_dir=\"./bert_logs\",\n",
        "    logging_steps=100,\n",
        "    warmup_steps=200,\n",
        "    weight_decay=0.1,\n",
        "    gradient_accumulation_steps=4,\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    max_grad_norm=1.0,\n",
        "\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model='full_order_accuracy',\n",
        "    greater_is_better=True,\n",
        "    seed=42,\n",
        "    fp16=True,\n",
        "\n",
        "    # ğŸ’¡ í•µì‹¬ ìˆ˜ì •\n",
        "    ddp_find_unused_parameters=False,   # DDP ë¬¸ì œ ë°©ì§€\n",
        "    dataloader_pin_memory=True,\n",
        ")\n",
        "\n",
        "# Trainer ì„¤ì • (ì „ì²´ í•™ìŠµìš©)\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2, early_stopping_threshold=0.005)]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_Tn5Pe8iV5_"
      },
      "source": [
        "# í•™ìŠµ ì‹¤í–‰"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "U9B49-xDiV5_"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2755' max='2755' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2755/2755 12:26, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Full Order Accuracy</th>\n",
              "      <th>Sentence Accuracy</th>\n",
              "      <th>Kendall Tau</th>\n",
              "      <th>Spearman Rho</th>\n",
              "      <th>Adjacent Pair Accuracy</th>\n",
              "      <th>Long Range Pair Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.713100</td>\n",
              "      <td>0.583711</td>\n",
              "      <td>0.715233</td>\n",
              "      <td>0.867068</td>\n",
              "      <td>0.910835</td>\n",
              "      <td>0.943745</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.406400</td>\n",
              "      <td>0.362348</td>\n",
              "      <td>0.992603</td>\n",
              "      <td>0.996415</td>\n",
              "      <td>0.997359</td>\n",
              "      <td>0.998311</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.384700</td>\n",
              "      <td>0.358761</td>\n",
              "      <td>0.996571</td>\n",
              "      <td>0.998285</td>\n",
              "      <td>0.998734</td>\n",
              "      <td>0.999178</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2755, training_loss=0.5496384795477949, metrics={'train_runtime': 747.624, 'train_samples_per_second': 943.917, 'train_steps_per_second': 3.685, 'total_flos': 0.0, 'train_loss': 0.5496384795477949, 'epoch': 4.99546690843155})"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "64c9UrhAiV5_"
      },
      "outputs": [],
      "source": [
        "# checkpoints = [\"checkpoint-1103\", \"checkpoint-2206\", \"checkpoint-3309\"]\n",
        "# for ckpt in checkpoints:\n",
        "#     shutil.rmtree(f\"/content/roberta_results/{ckpt}\", ignore_errors=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-55qmPPoiV5_",
        "outputId": "de073553-4f3c-46c1-a4ee-c425a0b6f61f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('./bert_results/best_bert_model/tokenizer_config.json',\n",
              " './bert_results/best_bert_model/special_tokens_map.json',\n",
              " './bert_results/best_bert_model/vocab.txt',\n",
              " './bert_results/best_bert_model/added_tokens.json',\n",
              " './bert_results/best_bert_model/tokenizer.json')"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# best checkpoint ê¸°ì¤€ìœ¼ë¡œ ëª¨ë¸ ì €ì¥\n",
        "save_path = \"./bert_results/best_bert_model\"\n",
        "\n",
        "trainer.save_model(save_path)\n",
        "tokenizer.save_pretrained(save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZbjmSB1qvyn"
      },
      "source": [
        "# ì˜ˆì¸¡ ë° ì €ì¥"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-01T08:17:52.071041Z",
          "iopub.status.busy": "2025-06-01T08:17:52.070370Z",
          "iopub.status.idle": "2025-06-01T08:17:52.078354Z",
          "shell.execute_reply": "2025-06-01T08:17:52.077612Z",
          "shell.execute_reply.started": "2025-06-01T08:17:52.071008Z"
        },
        "id": "cnMgu5Ktqvyn",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def predict(model, test_df, tokenizer, device, batch_size=32):\n",
        "    test_dataset = GlobalOrderDataset(test_df, tokenizer, labels=None)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "\n",
        "            # ëª¨ë¸ ì¶œë ¥ì´ [batch, 4, 4] í˜•íƒœë¡œ ë‚˜ì˜´\n",
        "            # ê° ë¬¸ì¥ë³„ë¡œ 4ê°œì˜ ìœ„ì¹˜ì— ëŒ€í•œ í™•ë¥ \n",
        "            logits = model(input_ids, attention_mask)['logits']\n",
        "\n",
        "            # ê° ë¬¸ì¥ì´ ì–´ë–¤ ìœ„ì¹˜ì— ê°€ì•¼í•˜ëŠ”ì§€ ì˜ˆì¸¡\n",
        "            # [batch, 4, 4] -> [batch, 4] (ê° ë¬¸ì¥ì˜ ìµœì  ìœ„ì¹˜)\n",
        "            preds = logits.argmax(-1).cpu().numpy()\n",
        "            all_preds.append(preds)\n",
        "\n",
        "    all_preds = np.concatenate(all_preds, axis=0)\n",
        "\n",
        "    # [ë¬¸ì¥0ì€ ëª‡ ë²ˆì§¸, ...] â†’ [answer_0, answer_1, ...]ë¡œ ì—­ë³€í™˜\n",
        "    answers = []\n",
        "    for row in all_preds:\n",
        "        answer = [0] * 4\n",
        "        for sent_idx, pos in enumerate(row):\n",
        "            answer[pos] = sent_idx\n",
        "        answers.append(answer)\n",
        "\n",
        "    return np.array(answers)\n",
        "\n",
        "def save_submission(answers, submission_path, output_path):\n",
        "    sub = submission_path.copy()\n",
        "    for i in range(4):\n",
        "        sub[f'answer_{i}'] = answers[:, i]\n",
        "    sub.to_csv(output_path, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-01T08:17:54.491310Z",
          "iopub.status.busy": "2025-06-01T08:17:54.490618Z",
          "iopub.status.idle": "2025-06-01T08:18:37.884347Z",
          "shell.execute_reply": "2025-06-01T08:18:37.883567Z",
          "shell.execute_reply.started": "2025-06-01T08:17:54.491285Z"
        },
        "id": "ETwtfIxcqvyo",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ì œì¶œíŒŒì¼ ì €ì¥ ì™„ë£Œ\n"
          ]
        }
      ],
      "source": [
        "# ì˜ˆì¸¡ ìˆ˜í–‰\n",
        "answers = predict(\n",
        "    model=model,\n",
        "    test_df=test_path,\n",
        "    tokenizer=tokenizer,\n",
        "    device=device,\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "# ì œì¶œ íŒŒì¼ ì €ì¥\n",
        "save_submission(\n",
        "    answers=answers,\n",
        "    submission_path=submission_path,\n",
        "    output_path=f\"./data/submission_bert.csv\"\n",
        ")\n",
        "\n",
        "print(\"âœ… ì œì¶œíŒŒì¼ ì €ì¥ ì™„ë£Œ\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 7558757,
          "sourceId": 12014679,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 31040,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
